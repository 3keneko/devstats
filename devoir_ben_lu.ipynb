{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e1c6dc",
   "metadata": {},
   "source": [
    "$$Devoir  de  statistiques$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ee8cfa",
   "metadata": {},
   "source": [
    "## Exercice 1: ACP sur la matrice des distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731328be",
   "metadata": {},
   "source": [
    "### 1. Montrer que la matrice de variance-covariance empirique des $ X_i $ est $ S = X' DX $ \n",
    "__Preuve__:\n",
    "Soient $i, j \\in \\{ 1, \\dots , p \\}$, alors on remarque que\n",
    "\\begin{align}\n",
    "(S)_{ij} &= (X'DX)_{ij} \\\\ &= \\frac{1}{n} (X'X)_{ij} \\\\ &=  \\frac{1}{n} \\sum_{k=1}^n X_{ki} X_{kj} \\\\ &= \\frac{1}{n} \\sum_{k=0}^n \\left( X_{ki} - 0 \\right) \\left( X_{kj} - 0 \\right)\n",
    "\\end{align}\n",
    "On constate alors que $S$ correspond bien à la matrice de variance-covariance empirique des $X_i$ car ce sont des variables aléatoires centrées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e0651",
   "metadata": {},
   "source": [
    "### 2. Montrer que $\\forall i=1, \\dots ,n, d_i^2 = \\Vert X_i \\Vert^2_M + I_g $\n",
    "__Preuve__: Soient $ n \\in \\mathbb{N} $ et $ i\\in \\{ 1, \\dots, n \\} $ \n",
    "Calculons ici le membre de gauche de l'égalité afin de nous ramener au membre de droite \n",
    "\\begin{align}\n",
    "d^2_{i \\cdot} &= \\frac{1}{n} \\sum_{j=1}^n \\left( X_i - X_j \\right) ' M \\left( X_i - X_j \\right) \\\\ \n",
    "&= \\frac{1}{n} \\sum_{j=1}^n \\left( X_i ' M X_i  + X_j ' M X_j  - X_j ' M X_i - X_i ' M X_j \\right) \\\\\n",
    "&= \\frac{1}{n} \\sum_{j=1}^n \\left( \\Vert X_i \\Vert _M ^2 + \\Vert X_j \\Vert _M ^2 - X_j ' M X_i - X_i ' M X_j \\right) \\\\\n",
    "&= \\Vert X_i \\Vert _M ^2 + \\frac{1}{n} \\sum_{j=1}^n \\Vert X_j \\Vert _M ^2 -  X_i ' M \\frac{1}{n} \\underbrace{\\sum_{j=1}^n X_j}_0 - \\frac{1}{n} \\left( \\underbrace{\\sum_{j=1}^n X_j '}_0\\right) M X_i \\\\\n",
    "&= \\Vert X_i \\Vert _M ^2 + \\frac{1}{n} \\sum_{j=1}^n \\Vert X_j \\Vert _M ^2 \\\\\n",
    "&= \\Vert X_i \\Vert _M ^2 + I_g\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55d2f3",
   "metadata": {},
   "source": [
    "### 3. En déduire que $ d^2_{..} = 2I_g $ \n",
    "__Preuve__: Il s'agit encore une fois de calculer le terme de gauche\n",
    "\\begin{align}\n",
    "d^2_{..} = \\sum_{i=1}^n \\frac{1}{n} d^2_{i.}\n",
    "\\end{align}\n",
    "Par l'identité de l'exercice précédent, on a\n",
    "\\begin{align} \n",
    "\\sum_{i=1}^n \\frac{1}{n} d^2_{i.} &= \\frac{1}{n} \\sum_{i=1}^n \\left( \\Vert X_i \\Vert_M ^2 + I_g \\right) \\\\ \n",
    "&= I_g + \\frac{1}{n} \\sum_{i=1}^n \\Vert X_i \\Vert_M ^2  \\\\\n",
    "&= 2 I_g\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfa9bef",
   "metadata": {},
   "source": [
    "### 4. Posons W la matrice des produits scalaires et montrer que $ w_{ij} = - \\frac{ d^2_{ij} - d_{i.}^2 - d_{.j}^2 + d^2_{..}}{2} $\n",
    "__Preuve__: Le résultat suit d'un simple calcul\n",
    "\\begin{align}\n",
    " - \\frac{ d^2_{ij} - d_{i.}^2 - d_{.j}^2 + d^2_{..}}{2} &= - \\frac{\\langle X_i - X_j, X_i - X_j \\rangle _M  - \\langle X_i , X_i \\rangle _M - I_g - \\langle X_j , X_j \\rangle _M - I_g + 2 I_g }{2} \\\\\n",
    " &= - \\frac{- \\langle X_i, X_j \\rangle _M - \\langle X_j, X_i \\rangle _M }{2} \\\\\n",
    " &= \\langle X_i, X_j \\rangle _M \\\\\n",
    " &= w_{ij}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e14c1",
   "metadata": {},
   "source": [
    "### 5. Exprimer W en fonction  de $ \\mathcal{D} $ \n",
    "__Preuve__: Soit $ T \\in \\mathbb{R}^{n \\times n} $ la matrice telle que \n",
    "\\begin{equation}\n",
    "\\forall i, j \\in \\{1, ..., n \\}, \\quad  \\left( T \\right)_{ij} = \\frac{1}{n}\n",
    "\\end{equation}\n",
    "Alors, on a directement\n",
    "\\begin{equation}\n",
    "W = -\\frac{1}{2} \\left( \\mathcal{D} - T\\mathcal{D} - \\mathcal{D}T + T\\mathcal{D}T  \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a892951",
   "metadata": {},
   "source": [
    "### 6. Supposons dans la suite que l’ACP du nuage de X donne p axes principaux normés $(u_{k})_{k=1,...,p}$ de valeurs propres correspondantes $\\lambda_{k}$. Notons $v_{k}$ les composantes principales associées. Que peut-on en déduire ?\n",
    "__Preuve__: D'abord comme $ u_k $ est un axe principal, $u_k $ est en particulier un vecteur propre de S, par suite $ S u_k $ = $ \\lambda_k u_k $. \n",
    "\n",
    "Enfin, par définition de composante principale, on a\n",
    "\\begin{equation} X \\lambda_k u_k = \\lambda_k X u_k = \\lambda_k v_k \\end{equation}\n",
    "On en tire finalement que $ XSu_k = \\lambda_k v_k $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84d402",
   "metadata": {},
   "source": [
    "### 7. Montrer que, toujours si M = $I_{p}$, $v_{k}$est également vecteur propre de WD\n",
    "__Preuve__: Remarquons que $ v_k = X u_k $ où $ u_k $  représente le k-ième axe principal, donc il suffit de montrer que \n",
    "\\begin{equation}\n",
    "WDX u_k = \\lambda_k v_k \n",
    "\\end{equation}\n",
    "Remarquons que comme $ M = I_p $, on a $ W_{ij} = X'_i I_p X_j  = X_i' X_j $, et donc\n",
    "$ W = X X' $.\n",
    "\n",
    "Ainsi, \n",
    "\\begin{align} \n",
    "WDX u_k &= X \\underbrace{X' D X}_{S} u_k \\\\\n",
    "&= XS u_k \\\\ \n",
    "&= \\lambda_k v_k\n",
    "\\end{align}\n",
    "la dernière égalité s'obtient du résultat de la question précédente.\n",
    "\n",
    "Ainsi, en substituant $ X u_k $ par $ v_k $, on obtient $ WD v_k = \\lambda_k v_k $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2dd1b",
   "metadata": {},
   "source": [
    "### 8. Soit le vecteur $f_k \\in \\mathbb{R}^n$ dont la composante numéro i est $f_{ik} = \\sqrt{p_i}v_{ik }$ . En déduire que la matrice WD admet pour vecteur propre $f_k$ avec valeur propre associé à $\\lambda_{k}$.\n",
    "__Preuve__: On remarque que par définition de $ p_i $, pour tout $k \\in \\{1, ..., p \\}$ on  a l'égalité $ f_k = \\sqrt{\\frac{1}{n}}v_k $, comme $ v_k $ est une valeur propre de **WD** et comme $ f_k $ est un multiple scalaire de $v_k$, on conclut que $ f_k $ est également un vecteur propre de **WD**, appartenant au même sous-espace propre que $ v_k $ et est donc de valeur propre $ \\lambda _k $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c3263",
   "metadata": {},
   "source": [
    "### 9.Montrer que le vecteur $(\\sqrt p_{i} )_{i=1,...,n}$ est vecteur propre de WD associé à la valeur propre 0.\n",
    "__Preuve__: Soit $ v = \\begin{pmatrix} \\sqrt{p_1} \\\\ \\sqrt{p_2} \\\\ \\vdots \\\\ \\sqrt{p_n} \\end{pmatrix} $, remarqons d'abord que $ Dv = \\begin{pmatrix} \\sqrt{p_1^3} \\\\ \\sqrt{p_2^3} \\\\ \\vdots \\\\ \\sqrt{p_n^3} \\end{pmatrix} $.\n",
    "\n",
    "Ensuite, pour $ i \\in \\{1, ..., n\\}$, on a $ \\left( W \\begin{pmatrix} \\sqrt{p_1^3} \\\\ \\sqrt{p_2^3} \\\\ \\vdots \\\\ \\sqrt{p_n^3} \\end{pmatrix} \\right)_i = \\sum_{j=0}^n \\sqrt{p_j^3} W_{ij} $\n",
    "\n",
    "En utilisant la relation démontrée à l'exercice 4 pour remplacer $ W_{ij} $, on obtient\n",
    "\\begin{align}\n",
    "\\sum_{j=0}^n \\sqrt{p_j^3} W_{ij} &=  \\sum_{j=0}^n \\left(-\\frac{ d^2_{ij} - d_{i.}^2 - d_{.j}^2 + d^2_{..}}{2}\\right) \\sqrt{p_j^3} \\\\\n",
    "&= -\\frac{1}{2} \\left(\\sum_{j=0}^n d^2_{ij} \\sqrt{p_j^3} - \\sum_{j=0}^n d^2_{i.} \\sqrt{p_j^3} - \\sum_{j=0}^n d^2_{.j} \\sqrt{p_j^3} + \\sum_{j=0}^n d^2_{..} \\sqrt{p_j^3} \\right) \\\\\n",
    "&= -\\frac{1}{2} \\left( \\sqrt{p_j} d^2_{i.} - n \\sqrt{p_j^3} d^2_{i.} - \\sqrt{p_j}d^2_{..} + n \\sqrt{p_j^3} d^2_{..} \\right)\n",
    "\\end{align}\n",
    "Or, pour tout $ j \\in \\{1, ..., n\\}, \\quad p_j = \\frac{1}{n} $ donc $ n \\sqrt{p_i^3} = \\sqrt{p_j} $ \n",
    "\n",
    "Utiliser cette dernière relation nous donne\n",
    "\\begin{align} \n",
    " -\\frac{1}{2} \\left( \\underbrace{\\sqrt{p_j} d^2_{i.} - n \\sqrt{p_j^3} d^2_{i.}}_0 - \\underbrace{ \\sqrt{p_j}d^2_{..} + n \\sqrt{p_j^3} d^2_{..} }_0 \\right) &= 0\n",
    "\\end{align}\n",
    "\n",
    "Ainsi, on a bien que le vecteur $ (\\sqrt{p_i})_{i=1...n}) $ est bien un vecteur propre de **WD** dont la valeur propre associée est 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb0311",
   "metadata": {},
   "source": [
    "### 1.10 Montrer que $\\sum_{i=1}^{n} f_{ik}^{2}$=$\\lambda_{k}$ et pour tout k $\\neq $ l, $\\sum_{i=1}^{n}f_{ik}f_{il}$=0.\n",
    "On calcule directement:\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^{n} f_{ik}^{2} &= \\sum_{i=1}^{n} \\left(\\frac{1}{\\sqrt{n}} v_{ik} \\right)^{2} \\\\ &= \\frac{1}{n} \\sum_{i=1}^{n}v_{ik}^{2} \\\\ &= \\frac{1}{n} \\langle v_{k},v_{k} \\rangle \\\\ &= \\frac{1}{n} \\langle Xu_{k},Xu_{k}\\rangle \\\\ &= \\frac{1}{n} (u_{k}^{'}X^{'})(Xu_{k}) \\\\ &= u_{k}^{'}X^{'}(\\frac{1}{n} I_{n})Xu_{k} \\\\ &= u_{k}^{'}X^{'}DXu_{k}.\n",
    "\\end{align}\n",
    "Par définition S=$X^{'}DX$, et puisque $u_{k}$ est un vecteur propre de S de valeur propre $\\lambda_{k}$, on a alors \n",
    "\\begin{align}\n",
    "\\sum_{i=1}^{n} f_{ik}^{2} &= u_{k}^{'}Su_{k} \\\\ &= u_{k}^{'} \\lambda_{k} u_{k} \\\\ &= \\lambda_{k} u_{k}^{'} u_{k} \\\\ &= \\lambda_{k}.\n",
    "\\end{align}\n",
    "Où la dernière égalité tient puisque les $u_{k}$ sont de norme 1.\n",
    "Prenons maintenant k $\\neq$ l et calculons directement:\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^{n}f_{ik}f_{il} &= \\sum_{i=1}^{n} \\frac{1}{n} v_{ik}v_{il} \\\\ &= \\frac{1}{n} \\langle v_{k},v_{l} \\rangle \\\\ &= \\frac{1}{n} \\langle Xu_{k},Xu_{l} \\rangle \\\\ &= \\frac{1}{n} u_{k}^{'}X^{'}Xu_{l} \\\\ &= u_{k}^{'}X^{'}(\\frac{1}{n} I_{n})Xu_{k} \\\\ &= u_{k}^{'}Su_{l} \\\\ &= \\lambda_{l} u_{k}^{'}u_{l} \\\\ &= \\lambda_{l} \\langle u_{k},u_{l} \\rangle \\\\ &= \\lambda_{l} \\cdot 0 \\\\ &= 0\n",
    "\\end{align}\n",
    "puisque les vecteurs $u_{k}$ et $u_{l}$ sont orthogonaux entre eux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a676427",
   "metadata": {},
   "source": [
    "# Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a934c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PVP</th>\n",
       "      <th>AGR</th>\n",
       "      <th>CMI</th>\n",
       "      <th>TRA</th>\n",
       "      <th>LOG</th>\n",
       "      <th>EDU</th>\n",
       "      <th>ACS</th>\n",
       "      <th>ACO</th>\n",
       "      <th>DEF</th>\n",
       "      <th>DET</th>\n",
       "      <th>DIV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Annee1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annee2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>31.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annee3</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annee4</td>\n",
       "      <td>14.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>26.2</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Annee5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>27.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Annee6</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>25.3</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Annee7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Annee8</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Annee9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>42.4</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Annee10</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Annee11</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>41.6</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Annee12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Annee13</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>13.4</td>\n",
       "      <td>27.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Annee14</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Annee15</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>40.7</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Annee16</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>32.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Annee17</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>20.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Annee18</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>36.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Annee19</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Annee20</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Annee21</td>\n",
       "      <td>12.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Annee22</td>\n",
       "      <td>12.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Annee23</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Annee24</td>\n",
       "      <td>12.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>11.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   PVP  AGR   CMI   TRA   LOG   EDU   ACS   ACO   DEF   DET  DIV\n",
       "0      Annee1  18.0  0.5   0.1   6.7   0.5   2.1   2.0   0.0  26.4  41.5  2.1\n",
       "1      Annee2  14.1  0.8   0.1  15.3   1.9   3.7   0.5   0.0  29.8  31.3  2.5\n",
       "2      Annee3  13.6  0.7   0.7   6.8   0.6   7.1   0.7   0.0  33.8  34.4  1.7\n",
       "3      Annee4  14.3  1.7   1.7   6.9   1.2   7.4   0.8   0.0  37.7  26.2  2.2\n",
       "4      Annee5  10.3  1.5   0.4   9.3   0.6   8.5   0.9   0.0  38.4  27.2  3.0\n",
       "5      Annee6  13.4  1.4   0.5   8.1   0.7   8.6   1.8   0.0  38.5  25.3  1.9\n",
       "6      Annee7  13.5  1.1   0.5   9.0   0.6   9.0   3.4   0.0  36.8  23.5  2.6\n",
       "7      Annee8  12.9  1.4   0.3   9.4   0.6   9.3   4.3   0.0  41.1  19.4  1.3\n",
       "8      Annee9  12.3  0.3   0.1  11.9   2.4   3.7   1.7   1.9  42.4  23.1  0.2\n",
       "9     Annee10   7.6  1.2   3.2   5.1   0.6   5.6   1.8  10.0  29.0  35.0  0.9\n",
       "10    Annee11  10.5  0.3   0.4   4.5   1.8   6.6   2.1  10.1  19.9  41.6  2.3\n",
       "11    Annee12  10.0  0.6   0.6   9.0   1.0   8.1   3.2  11.8  28.0  25.8  2.0\n",
       "12    Annee13  10.6  0.8   0.3   8.9   3.0  10.0   6.4  13.4  27.4  19.2  0.0\n",
       "13    Annee14   8.8  2.6   1.4   7.8   1.4  12.4   6.2  11.3  29.3  18.5  0.4\n",
       "14    Annee15  10.1  1.1   1.2   5.9   1.4   9.5   6.0   5.9  40.7  18.2  0.0\n",
       "15    Annee16  15.6  1.6  10.0  11.4   7.6   8.8   4.8   3.4  32.2   4.6  0.0\n",
       "16    Annee17  11.2  1.3  16.5  12.4  15.8   8.1   4.9   3.4  20.7   4.2  1.5\n",
       "17    Annee18  12.9  1.5   7.0   7.9  12.1   8.1   5.3   3.9  36.1   5.2  0.0\n",
       "18    Annee19  10.9  5.3   9.7   7.6   9.6   9.4   8.5   4.6  28.2   6.2  0.0\n",
       "19    Annee20  13.1  4.4   7.3   5.7   9.8  12.5   8.0   5.0  26.7   7.5  0.0\n",
       "20    Annee21  12.8  4.7   7.5   6.6   6.8  15.7   9.7   5.3  24.5   6.4  0.1\n",
       "21    Annee22  12.4  4.3   8.4   9.1   6.0  19.5  10.6   4.7  19.8   3.5  1.8\n",
       "22    Annee23  11.4  6.0   9.5   5.9   5.0  21.1  10.7   4.2  20.0   4.4  1.9\n",
       "23    Annee24  12.8  2.8   7.1   8.5   4.0  23.8  11.3   3.7  18.8   7.2  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "seaborn.set_style(\"white\")\n",
    "%matplotlib inline\n",
    "\n",
    "depenses_complet = pd.read_csv(\"DataDepenses.csv\", sep=\";\", header=1)\n",
    "depenses_complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc4af53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "numeric_depenses = depenses_complet.drop(columns=[\"Unnamed: 0\"])\n",
    "pca = PCA()\n",
    "pca.fit(numeric_depenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5979f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.13585539e+02 5.82521023e+01 2.29070891e+01 1.71155030e+01\n",
      " 5.76650184e+00 3.21652260e+00 1.15873285e+00 1.10189812e+00\n",
      " 6.59827832e-01 2.58617864e-01 1.28898373e-04]\n",
      "[6.59168926e-01 1.79777975e-01 7.06959907e-02 5.28219643e-02\n",
      " 1.77966113e-02 9.92685063e-03 3.57608802e-03 3.40068434e-03\n",
      " 2.03636447e-03 7.98147945e-04 3.97806905e-07]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32e28edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "y = [*pca.explained_variance_ratio_]\n",
    "x = range(len(y))\n",
    "ycum = np.cumsum(y)\n",
    "plt.plot(x, y, '.b')\n",
    "plt.plot(x, ycum, \"-r\")\n",
    "plt.title(\"Somme des variances expliquées\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7d2d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depenses_pca = pca.transform(numeric_depenses)\n",
    "depenses_pca_df = pd.DataFrame({\n",
    "    \"Dim1\": depenses_pca[:,0],\n",
    "    \"Dim2\": depenses_pca[:,1],\n",
    "    \"Année\": depenses_complet[\"Unnamed: 0\"]\n",
    "})\n",
    "depenses_pca_df.plot.scatter(\"Dim1\", \"Dim2\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "116be63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22.60253111  14.34979125  17.11958588  10.66851141  11.81245219\n",
      "  10.00680364   7.72813742   5.0496214   10.08986847  15.47347034\n",
      "  19.09388231   7.23404222  -0.09544993  -0.83272799   2.88488398\n",
      " -13.74656772 -20.25387408 -12.43957011 -15.04981969 -14.3575281\n",
      " -16.44128304 -21.16888534 -20.99618826 -18.73168736]\n",
      "[  7.78626986   0.67777835   0.15284473  -5.96523215  -6.01778416\n",
      "  -6.76236437  -5.8195178  -10.78352473 -11.72069892   8.00861407\n",
      "  17.9641921    5.99210172   5.19033056   3.5707034   -8.28684798\n",
      "  -7.72416756   1.98259199 -10.44822177  -2.1076497    0.18280216\n",
      "   2.57187114   5.98316889   6.88711201   8.68562816]\n"
     ]
    }
   ],
   "source": [
    "print(depenses_pca[:,0])\n",
    "print(depenses_pca[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b257144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Variance expliquée</th>\n",
       "      <th>% variance expliquée</th>\n",
       "      <th>% cum. var. expliquée</th>\n",
       "      <th>Difference avec valeur propre moyenne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dim1</td>\n",
       "      <td>213.585539</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>184.128952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dim2</td>\n",
       "      <td>58.252102</td>\n",
       "      <td>18.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>28.795515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dim3</td>\n",
       "      <td>22.907089</td>\n",
       "      <td>7.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-6.549499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dim4</td>\n",
       "      <td>17.115503</td>\n",
       "      <td>5.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-12.341085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dim5</td>\n",
       "      <td>5.766502</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-23.690086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dim6</td>\n",
       "      <td>3.216523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-26.240065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dim7</td>\n",
       "      <td>1.158733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-28.297855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dim8</td>\n",
       "      <td>1.101898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-28.354689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dim9</td>\n",
       "      <td>0.659828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-28.796760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dim10</td>\n",
       "      <td>0.258618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-29.197970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dim11</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-29.456459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dimension  Variance expliquée  % variance expliquée  % cum. var. expliquée  \\\n",
       "0       Dim1          213.585539                  66.0                   66.0   \n",
       "1       Dim2           58.252102                  18.0                   84.0   \n",
       "2       Dim3           22.907089                   7.0                   91.0   \n",
       "3       Dim4           17.115503                   5.0                   96.0   \n",
       "4       Dim5            5.766502                   2.0                   98.0   \n",
       "5       Dim6            3.216523                   1.0                   99.0   \n",
       "6       Dim7            1.158733                   0.0                   99.0   \n",
       "7       Dim8            1.101898                   0.0                  100.0   \n",
       "8       Dim9            0.659828                   0.0                  100.0   \n",
       "9      Dim10            0.258618                   0.0                  100.0   \n",
       "10     Dim11            0.000129                   0.0                  100.0   \n",
       "\n",
       "    Difference avec valeur propre moyenne  \n",
       "0                              184.128952  \n",
       "1                               28.795515  \n",
       "2                               -6.549499  \n",
       "3                              -12.341085  \n",
       "4                              -23.690086  \n",
       "5                              -26.240065  \n",
       "6                              -28.297855  \n",
       "7                              -28.354689  \n",
       "8                              -28.796760  \n",
       "9                              -29.197970  \n",
       "10                             -29.456459  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eig = pd.DataFrame(\n",
    "    {\n",
    "        \"Dimension\" : [\"Dim\" + str(x + 1) for x in range(len(pca.explained_variance_))], \n",
    "        \"Variance expliquée\" : pca.explained_variance_,\n",
    "        \"% variance expliquée\" : np.round(pca.explained_variance_ratio_ * 100),\n",
    "        \"% cum. var. expliquée\" : np.round(np.cumsum(pca.explained_variance_ratio_) * 100),\n",
    "        \"Difference avec valeur propre moyenne\":\n",
    "        [x - np.mean(pca.explained_variance_) for x in pca.explained_variance_],\n",
    "    }\n",
    ")\n",
    "eig.name = \"Tableau 1\"\n",
    "eig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092a208",
   "metadata": {},
   "source": [
    "## 2.2 Combien d'axes retiendrez-vous pour cette analyse?\n",
    "On rappelle les règles qui nous permettent de rchoisir combien d'axes principaux nous retiendrons:\n",
    "- D'après la règle de Kaiser, comme les deux premières valeurs propres sont supérieures à la moyenne des valeurs propres, en regardant la dernière colonne du tableau précédent, on ne garde donc que les deux premières composantes principales.\n",
    "- Selon la règle du pouce, comme les deux premières valeurs propres expliquent plus de 80% (ici même 84%) de la variance, on ne devrait garder que les deux premières valeurs propres.\n",
    "- Selon la règle du coude, en regardant le graphique \"somme des variances expliquées\", on devrait garder les 4 premières composantes principales.\n",
    "\n",
    "#### Synthèse\n",
    "Comme il est d'une part plus facile de représenter les données sur un plan 2D, et que de plus, en pratique, la règle du pouce et la règle de Kaiser sont plus fiables que la règle du coude, nous choisirons ici de garder uniquement les deux premières composantes principales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0f536",
   "metadata": {},
   "source": [
    "### 2.3 Donner une interprétation globale des dépenses sur les axes retenus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3adb1c",
   "metadata": {},
   "source": [
    "# Exercice 3 : Convergence des vecteurs propres d’une matrice de variance-covariance empirique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d920b05",
   "metadata": {},
   "source": [
    "Ici sont définies des macros LaTeX utilisées tout au long de la résolution de cet exercice (cliquez sur ce texte pour les voir)\n",
    "$\\newcommand{\\ub}{\\hat{\\beta}}$\n",
    "$\\newcommand{\\uS}{\\hat{S}}$\n",
    "$\\newcommand{\\uL}{\\hat{\\varLambda}}$\n",
    "$\\newcommand{\\eqDist}{\\overset{\\mathcal{D}}{=} } $\n",
    "$\\newcommand{\\tT}{\\hat{\\Theta}} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d9560",
   "metadata": {},
   "source": [
    "### 1. Montrer que $\\sqrt{n} (\\uL − Ip) = O_P(1)$ pour $n \\to \\infty$.\n",
    "Par le TCL, nous avons \n",
    "\\begin{equation}\n",
    "\\sqrt{n} \\left( \\uS - I_p \\right) = O_P(1), \\quad n \\to \\infty  \\tag{*}\n",
    "\\end{equation}\n",
    "Remarquons alors que pour tout $ n \\in \\mathbb{N} $ \n",
    "\\begin{align}\n",
    "\\sqrt{n} \\left( \\uS - I_p \\right) &= \\sqrt{n} \\left( \\ub \\uL \\ub' - \\ub \\ub' \\right) \\\\\n",
    "&= \\ub \\sqrt{n} \\left( \\uL - I_p \\right) \\ub'\n",
    "\\end{align}\n",
    "On en déduit alors que, puisque $\\ub$ est dans $S\\mathcal{O}_p$, pour tout $ n \\in \\mathbb{N} $\n",
    "\\begin{align}\n",
    "\\ub' \\sqrt{n} \\left( \\uS - I_p \\right) \\ub &= \\sqrt{n} \\left( \\uL - I_p \\right)\n",
    "\\end{align}\n",
    "En faisant tendre n vers $ +\\infty $ et en utilisant cette dernière égalité et en l'injectant dans (*), on obtient\n",
    "\\begin{align}\n",
    "\\sqrt{n} \\left( \\uL - I_p \\right) = \\ub' \\sqrt{n} \\left( \\uS - I_p \\right) \\ub \n",
    "\\end{align}\n",
    "En appliquant Cauchy-Scwharz au terme de droite de cette dernière équation on obtient que\n",
    "\\begin{align}\n",
    "\\Vert \\ub' \\sqrt{n} \\left( \\uS - I_p \\right) \\ub \\Vert \\leq \\underbrace{\\Vert \\ub' \\Vert}_1 \\sqrt{n} \\Vert  \\left( \\uS - I_p \\right) \\Vert \\Vert \\underbrace{\\Vert \\ub \\Vert}_1\n",
    "\\end{align}\n",
    "Et donc, en particulier,\n",
    "\\begin{equation}\n",
    "\\sqrt{n} \\Vert \\left( \\uL - I_p \\right) \\Vert \\leq \\sqrt{n} \\Vert  \\left( \\uS - I_p \\right) \\Vert\n",
    "\\end{equation}\n",
    "Comme le terme de droite de cette dernière équation est borné en probabilité, le terme de gauche l'est également, et donc \n",
    "\\begin{equation}\n",
    "\\sqrt{n} \\left( \\uL - I_p \\right) = O_P(1), \\quad n \\to \\infty\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9207f",
   "metadata": {},
   "source": [
    "### 2. Montrer que pour toute matrice $ \\Theta ∈ S\\mathcal{O}_p , $ $ \\Theta \\sqrt{n} (\\uS − I_p)\\varTheta′ \\overset{\\mathcal{D}}{=} \\sqrt{n}(\\uS − I_p)$.\n",
    "\n",
    "Tout d'abord, puisque $\\uS$ est un variable aléatoire de loi Wishart, que l'on peut écrire pour des $Z_{i}$ de loi $\\mathcal{N}_{p}(0,I_{p})$,\n",
    "\\begin{equation}\n",
    "\\uS = \\sum_{i=1}^{n} Z_{i}Z_{i}^{'}.\n",
    "\\end{equation}\n",
    "On a alors, par calculs directs,\n",
    "\\begin{align}\n",
    "\\Theta \\sqrt{n} \\left( \\uS - I_{p} \\right) \\Theta^{'}  & \\eqDist \\sqrt{n} \\left( \\Theta \\left( \\sum_{i=1}^{n} Z_{i}Z_{i}^{'} \\right) \\Theta^{'} - \\Theta \\Theta' \\right) \\\\ & \\eqDist \\sqrt{n} \\left(  \\sum_{i=1}^{n} \\Theta Z_{i}Z_{i}^{'} \\Theta^{'} - I_{p} \\right) \\\\ & \\eqDist \\sqrt{n} \\left(  \\sum_{i=1}^{n} \\underbrace{\\Theta Z_{i}}_{\\mathcal{N}_{p}(0, I_{p})} \\left(\\Theta Z_{i} \\right)^{'} - I_{p} \\right) .\n",
    "\\end{align}\n",
    "La deuxième égalité tient puisque $\\Theta$ est une matrice orthogonale. On remarque maintenant que puisque \n",
    "\\begin{equation}\n",
    "\\uS \\eqDist \\sum_{i=1}^{n} \\left(\\Theta Z_{i} \\left(\\Theta Z_{i} \\right)^{'} \\right).\n",
    "\\end{equation}\n",
    "alors on a bien que \n",
    "\\begin{equation}\n",
    "\\Theta \\sqrt{n} \\left( \\uS - I_{p} \\right) \\Theta^{'} \\eqDist \\sqrt{n} \\left( \\uS - I_{p} \\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d71a16",
   "metadata": {},
   "source": [
    "### 3. Montrer qu'il existe $ \\tT \\in S\\mathcal{O}_p $ tel que $ \\tT \\sqrt{n} \\left( \\uL - I_p \\right) \\tT' $ et $ \\sqrt{n} \\left( \\uL - I_p \\right) $ ne convergent pas vers la même distribution.\n",
    "\n",
    "Remarquons d'abord que dans le cas p=1, une telle matrice ne peut exister, comme les côtés droits et gauches de l'équation sont rigoureusement les mêmes.\n",
    "Prenons le cas p=2, considérons la matrice \n",
    "\\begin{equation}\n",
    "T = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}\n",
    "\\end{equation}\n",
    "Remarquons d'abord que $ T \\in S\\mathcal{O}_2 $, en effet, $\\vert T \\vert$ = 1 et \n",
    "\\begin{equation}\n",
    "T \\cdot T^{'} = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}  \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Dès lors, soient $ \\lambda_1 $ et $ \\lambda_2 $ des valeurs propres de $ \\uS $ et supposons $ \\lambda_1 > \\lambda_2 $.\n",
    "Alors, on a \n",
    "\n",
    "\\begin{align}\n",
    " T \\sqrt{n} (\\uL - I_2 ) T' &= \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} \\sqrt{n} \\left( \\begin{pmatrix} \\lambda_1 & 0 \\\\ 0 & \\lambda_2 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right) \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix} \\\\ &= \\sqrt{n} \\begin{pmatrix} \\lambda_2 - 1 & 0 \\\\ 0 & \\lambda_1 - 1 \\end{pmatrix}\n",
    " \\end{align}\n",
    " \n",
    " Puisque par hypothèse on a que $\\lambda_{1}$ > $\\lambda_{2}$, nous allons considérer l'événement\n",
    " \\begin{align}\n",
    " \\omega &= \\left\\{ \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\rvert  b=0, c=0, a>d \\right\\}.\n",
    " \\end{align}\n",
    " Puisque $ \\lambda_1 > \\lambda_2 $, on a que pour chaque n$\\geq$0,\n",
    " \\begin{align}\n",
    " \\mathbb{P} \\left[\\sqrt{n}(\\uL - I_{2}) \\in \\omega \\right] &= 1 \\\\ \\mathbb{P} \\left[\\sqrt{n} \\left(\\tT \\uL \\tT^{'} - I_{2} \\right) \\in \\omega \\right] &= 0\n",
    " \\end{align}\n",
    " Donc en particulier quand on prend la limite pour n qui tend vers l'infini,\n",
    " \\begin{align}\n",
    " \\mathbb{P} \\left[\\lim_{n \\to \\infty} \\sqrt{n}(\\uL - I_{2}) \\in \\omega \\right] &= \\lim_{n \\to \\infty} \\mathbb{P} \\left[\\sqrt{n}(\\uL - I_{2}) \\in \\omega \\right] \\\\ &= \\lim_{n \\to \\infty}  1 \\\\ &= 1.\n",
    " \\end{align}\n",
    " Aussi,\n",
    " \\begin{align}\n",
    " \\mathbb{P} \\left[\\lim_{n \\to \\infty} \\sqrt{n}(\\tT \\uL \\tT^{'}- I_{2}) \\in \\omega \\right] &= \\lim_{n \\to \\infty} \\mathbb{P} \\left[ \\sqrt{n}(\\tT \\uL \\tT^{'} - I_{2}) \\in \\omega \\right] \\\\ &= \\lim_{n \\to \\infty} 0 \\\\ &= 0.\n",
    " \\end{align}\n",
    " Il vient donc que $\\sqrt{n}(\\tT \\uL \\tT^{'} - I_{2})$ et $\\sqrt{n}(\\uL - I_{2})$ ne convergent pas vers la même distribution. On a fait ce raisonnement pour p=2, mais on remarque facilement qu'il se généralise à n'importe quel p>2 tout simplement en prenant l'ensemble des matrices diagonales diag($a_{1}$,...,$a_{p}$) avec $a_{1}$ > $a_{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5006e",
   "metadata": {},
   "source": [
    "### 4. Montrer que les trois premières questions impliquent qu'il n'existe pas de matrice $ \\beta $ telle que $ \\hat{\\beta} = \\beta + o_p(1) $ pour $ n \\to \\infty $\n",
    "\n",
    "Supposons qu'une telle matrice existe. \n",
    "Soit $ \\tT \\in S \\mathcal{O}_p$ comme dans le point précédent, c'est-à-dire telle que $ \\tT \\sqrt{n} \\left( \\uL - I_p \\right) \\tT ' $ et $ \\sqrt{n} \\left( \\uL - I_p \\right) $ ne convergent pas vers la même distribution. On considère alors pour n assez grand,\n",
    "\n",
    "\\begin{align}\n",
    "\\underbrace{\\tT \\beta'}_{S \\mathcal{O}_P } \\sqrt{n} \\left( \\uS - I_p \\right) \\underbrace{\\left (\\tT \\beta' \\right)' }_{S \\mathcal{O}_P } \\eqDist \\tT \\sqrt{n} \\left( \\uL - I_p \\right) \\tT '\n",
    "\\end{align}\n",
    "ce qui ne converge pas vers la même distribution que $ \\sqrt{n} \\left( \\uL - I_p \\right) $ par hypothèse.\n",
    "\n",
    "Considérons la fonction continue (ses composates sont des polynômes)\n",
    "\\begin{align}\n",
    "g: Mat_{p} \\left(\\mathbb{R} \\right) \\times Mat_{p} \\left(\\mathbb{R} \\right) \\to Mat_{p} \\left(\\mathbb{R} \\right), (a, b) \\mapsto b^{'}ab.\n",
    "\\end{align} \n",
    "Par le TCL, on a \n",
    "\\begin{align}\n",
    "\\sqrt{n} \\left( \\uS - I_{p} \\right) \\overset{\\mathcal{D}}{\\to} Y.\n",
    "\\end{align}\n",
    "Puisque par hypothèse on a que $\\ub \\overset{\\mathcal{D}}{\\to} \\beta$, on a grâce au lemme de Slutzky\n",
    "\\begin{align}\n",
    "(\\sqrt{n}\\left(\\uS - I_{p} \\right), \\ub) \\overset{\\mathcal{D}}{\\to} (Y, \\beta).\n",
    "\\end{align}\n",
    "Par continuité de la fonction g, on a que\n",
    "\\begin{align}\n",
    "g(\\sqrt{n}\\left(\\uS - I_{p} \\right), \\ub) &= \\ub' \\sqrt{n} \\left(\\uS - I_{p} \\right) \\ub \\overset{\\mathcal{D}}{\\to}  \\beta' Y \\beta.\n",
    "\\end{align}\n",
    "Or, par définition,\n",
    "\\begin{align}\n",
    "\\ub' \\sqrt{n} \\left(\\uS - I_{p} \\right) \\ub &= \\sqrt{n} \\left(\\uL - I_{p} \\right) .\n",
    "\\end{align}\n",
    "Et donc comme le membre de gauche de cette égalité converge, on a que le membre de droite de cette égalité converge également, dans la suite, nous notons X la variable aléatoire vers laquelle le membre de droite converge.\n",
    "\n",
    "Ainsi, on remarquons d'abord que par Slutzky\n",
    "\\begin{align} \n",
    "\\beta' \\sqrt{n} \\left(\\uS - I_p \\right) \\beta \\eqDist \\sqrt{n} \\left( \\uL - I_p \\right) \\tag{a}\n",
    "\\end{align} \n",
    "\n",
    "Or par l'exercice 3.2, on a également que \n",
    "\\begin{align}\n",
    "\\beta' \\sqrt{n} \\left(\\uS - I_p \\right) \\beta & \\eqDist  \\sqrt{n} \\left( \\uS - I_p \\right)  \\\\ & \\eqDist\n",
    "\\underbrace{\\tT \\beta'}_{S \\mathcal{O}_P } \\sqrt{n} \\left( \\uS - I_p \\right) \\underbrace{\\left (\\tT \\beta' \\right)' }_{S \\mathcal{O}_P }  \\\\ & \\eqDist \\tT \\underbrace{\\beta' \\sqrt{n} \\left( \\uS - I_p \\right) \\beta }_{\\sqrt{n} \\left( \\uL - I_p \\right)} \\tT' \\\\ & \\eqDist \\tT \\sqrt{n} \\left( \\uL - I_p \\right) \\tT' \\tag{b}\n",
    "\\end{align}  \n",
    "\n",
    "Ainsi, en comparant (a) et (b) et en utilisant le résultat montré à l'exercice 3.3, on aboutit à une contradiction.\n",
    "\n",
    "Et donc, on conclut qu'une telle matrice $ \\beta $ n'existe pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf6fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51daa4c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496fd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
